{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab 3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1h35aMtoTI7b",
        "outputId": "86f460da-fbf3-495b-9288-19549e3e20e4"
      },
      "source": [
        "!git clone https://github.com/chrishendra93/MI_Workshop\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'MI_Workshop'...\n",
            "remote: Enumerating objects: 74, done.\u001b[K\n",
            "remote: Counting objects: 100% (74/74), done.\u001b[K\n",
            "remote: Compressing objects: 100% (57/57), done.\u001b[K\n",
            "remote: Total 74 (delta 30), reused 46 (delta 16), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (74/74), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd-0YK5MzfcZ"
      },
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68iJXH7HEdFd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fcc4668-a292-497d-dd05-af881ad0b035"
      },
      "source": [
        "# Setting random seed so that everything is replicable\n",
        "\n",
        "np.random.seed(0)\n",
        "torch.random.manual_seed(0)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f890acbba10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0wmIe0PEfVs",
        "outputId": "dc7843d3-c250-4633-deb5-65d345f495f7"
      },
      "source": [
        "root_dir = \"/content/MI_Workshop/mnist_clr\"\n",
        "data_dir = \"/content/MI_Workshop/lab_3\"\n",
        "\n",
        "mnist_columns = [\"label\"] + [\"features_{}\".format(i) for i in range(28 ** 2)]\n",
        "mnist_train = pd.read_csv(\"./sample_data/mnist_train_small.csv\", names=mnist_columns)\n",
        "mnist_test = pd.read_csv(\"./sample_data/mnist_test.csv\", names=mnist_columns)\n",
        "mnist_arr_train = mnist_train[[\"features_{}\".format(i) for i in range(28 ** 2)]].values\n",
        "mnist_arr_test = mnist_test[[\"features_{}\".format(i) for i in range(28 ** 2)]].values\n",
        "\n",
        "X_train = np.load(os.path.join(root_dir, \"train_features.npy\"))\n",
        "X_test = np.load(os.path.join(root_dir, \"test_features.npy\"))\n",
        "y_train = np.load(os.path.join(root_dir, \"train_labels.npy\"))\n",
        "y_test = np.load(os.path.join(root_dir, \"test_labels.npy\"))\n",
        "\n",
        "print(np.all(y_train == mnist_train[\"label\"].values))\n",
        "print(np.all(y_test == mnist_test[\"label\"].values))\n",
        "\n",
        "train_bags, train_labels = np.load(os.path.join(data_dir, \"train_bags.npy\"), allow_pickle=True), np.load(os.path.join(data_dir, \"train_labels.npy\"),allow_pickle=True)\n",
        "test_bags, test_labels = np.load(os.path.join(data_dir, \"test_bags.npy\"), allow_pickle=True), np.load(os.path.join(data_dir, \"test_labels.npy\"), allow_pickle=True)\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hs3FBTyQE8Pp"
      },
      "source": [
        "# Visualize distribution of labels in train and test sets\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Azt-0CNME9d0"
      },
      "source": [
        "# Visualize distribution of instances in train and test sets\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXT6FaKYFos0"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import BCELoss\n",
        "from torch.optim import LBFGS, Adam\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFYoZ0_cGP7Y"
      },
      "source": [
        "class LogisticRegressionMI(nn.Module):\n",
        "\n",
        "  def __init__(self, n_dim, mode='max'):\n",
        "    super(LogisticRegressionMI, self).__init__()\n",
        "    if mode not in ('max', 'mean'):\n",
        "      raise ValueError(\"Invalid mode {}, must be one of max or mean\".format(mode))\n",
        "    self.mode = mode\n",
        "    self.encoder = nn.Linear(n_dim, 1)\n",
        "    \n",
        "  def forward(self, x, indices):\n",
        "    x = self.encoder(x)\n",
        "    x = torch.sigmoid(x)\n",
        "    if self.mode == 'max':\n",
        "      x = torch.stack([torch.max(x[idx]) for idx in indices])\n",
        "    else:\n",
        "      x = torch.stack([torch.mean(x[idx]) for idx in indices])\n",
        "    return x\n",
        "  \n",
        "  def get_max_indices(self, x, indices):\n",
        "    x = self.encoder(x)\n",
        "    x = torch.sigmoid(x)\n",
        "    pred, max_indices = [], []\n",
        "    for idx in indices:\n",
        "      max_idx = torch.argmax(x[idx])\n",
        "      max_indices.append(idx[max_idx])\n",
        "      pred.append(x[idx][max_idx])\n",
        "    return torch.cat(pred), np.array(max_indices)\n",
        "    "
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69IpL8GUIYx9"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, roc_curve, precision_recall_curve, auc\n",
        "from scipy.stats import mode\n",
        "\n",
        "def get_roc_auc(y_true, y_pred):\n",
        "    fpr, tpr, _  = roc_curve(y_true, y_pred)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    return roc_auc\n",
        "\n",
        "\n",
        "def get_pr_auc(y_true, y_pred):\n",
        "    precision, recall, _ = precision_recall_curve(y_true, y_pred, pos_label=1)\n",
        "    pr_auc = auc(recall, precision)\n",
        "    return pr_auc\n",
        "\n",
        "\n",
        "def get_accuracy(y_true, y_pred):\n",
        "    return balanced_accuracy_score(y_true, y_pred)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFPi7CVBHDA7",
        "outputId": "a994a71b-3ca1-46b5-ffd9-3eb80449a25e"
      },
      "source": [
        "logit_mi = LogisticRegressionMI(64, mode='mean')\n",
        "criterion = BCELoss()\n",
        "optimizer = LBFGS(logit_mi.parameters(), lr=0.001, max_iter=1000)\n",
        "logit_mi.train()\n",
        "\n",
        "\n",
        "def closure():\n",
        "    optimizer.zero_grad()\n",
        "    output = logit_mi(torch.Tensor(X_train), train_bags)\n",
        "    loss = criterion(output, torch.Tensor(train_labels))\n",
        "    loss.backward()\n",
        "    return loss\n",
        "\n",
        "optimizer.step(closure) \n",
        "\n",
        "logit_mi.eval()\n",
        "with torch.no_grad():\n",
        "  y_pred_logit_mi_test = logit_mi(torch.Tensor(X_test), test_bags).detach().numpy()\n",
        "  print(\"ROC AUC: {}\".format(get_roc_auc(test_labels, y_pred_logit_mi_test)))\n",
        "  print(\"PR AUC: {}\".format(get_pr_auc(test_labels, y_pred_logit_mi_test)))\n",
        "  print(\"Accuracy Score: {}\".format(accuracy_score(test_labels, y_pred_logit_mi_test >= 0.5)))\n",
        "  print(\"Balanced Accuracy Score: {}\".format(balanced_accuracy_score(test_labels, y_pred_logit_mi_test >= 0.5)))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROC AUC: 0.8444277901716553\n",
            "PR AUC: 0.3773344528695057\n",
            "Accuracy Score: 0.8806306306306306\n",
            "Balanced Accuracy Score: 0.49974437627811863\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ixa2BZ4fceN",
        "outputId": "14fb0cee-c04d-4896-8839-b4f4a31d4a8b"
      },
      "source": [
        "logit_mi = LogisticRegressionMI(64, mode='max')\n",
        "\n",
        "classes, counts = np.unique(train_labels, return_counts=True)\n",
        "class_weights = 1./torch.tensor(counts, dtype=torch.float)\n",
        "class_weights = class_weights / class_weights.sum()\n",
        "weights = torch.zeros(len(train_labels))\n",
        "weights[np.argwhere(train_labels == 0)] = class_weights[0] / counts[0]\n",
        "weights[np.argwhere(train_labels == 1)] = class_weights[1] / counts[1]\n",
        "\n",
        "criterion = BCELoss(weight=weights)\n",
        "\n",
        "logit_mi.train()\n",
        "\n",
        "\n",
        "optimizer = Adam(logit_mi.parameters(), lr=4e-3)\n",
        "n_epochs = 100\n",
        "\n",
        "for i in range(n_epochs):\n",
        "  optimizer.zero_grad()\n",
        "  output = logit_mi(torch.Tensor(X_train), train_bags)\n",
        "  loss = criterion(output, torch.Tensor(train_labels))\n",
        "  loss.backward()\n",
        "  optimizer.step() \n",
        "\n",
        "logit_mi.eval()\n",
        "with torch.no_grad():\n",
        "  y_pred_logit_mi_test = logit_mi(torch.Tensor(X_test), test_bags).detach().numpy()\n",
        "  print(\"ROC AUC: {}\".format(get_roc_auc(test_labels, y_pred_logit_mi_test)))\n",
        "  print(\"PR AUC: {}\".format(get_pr_auc(test_labels, y_pred_logit_mi_test)))\n",
        "  print(\"Accuracy Score: {}\".format(accuracy_score(test_labels, y_pred_logit_mi_test >= 0.5)))\n",
        "  print(\"Balanced Accuracy Score: {}\".format(balanced_accuracy_score(test_labels, y_pred_logit_mi_test >= 0.5)))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROC AUC: 0.7338860228047344\n",
            "PR AUC: 0.23332103380168645\n",
            "Accuracy Score: 0.11891891891891893\n",
            "Balanced Accuracy Score: 0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Wnn4uwwhLos"
      },
      "source": [
        "class nnMI(nn.Module):\n",
        "\n",
        "  def __init__(self, encoder, mode='max'):\n",
        "    super(nnMI, self).__init__()\n",
        "    if mode not in ('max', 'mean'):\n",
        "      raise ValueError(\"Invalid mode {}, must be one of max or mean\".format(mode))\n",
        "    self.mode = mode\n",
        "    self.encoder = encoder\n",
        "    \n",
        "  def forward(self, x, indices):\n",
        "    x = self.encoder(x)\n",
        "    if self.mode == 'max':\n",
        "      x = torch.stack([torch.max(x[idx]) for idx in indices])\n",
        "    else:\n",
        "      x = torch.stack([torch.mean(x[idx]) for idx in indices])\n",
        "    return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uosDU4swHEgs",
        "outputId": "1f891ce3-eccc-483d-ef96-7186555516c2"
      },
      "source": [
        "device = 'cuda'\n",
        "\n",
        "nn_mi = nnMI(nn.Sequential(*[nn.Linear(64, 128), nn.ReLU(),\n",
        "                             nn.Linear(128, 64), nn.ReLU(),\n",
        "                             nn.Linear(64, 1)]), mode='max').to(device)\n",
        "\n",
        "classes, counts = np.unique(train_labels, return_counts=True)\n",
        "class_weights = 1 /torch.tensor(counts, dtype=torch.float)\n",
        "class_weights = class_weights / class_weights.sum()\n",
        "\n",
        "weights = torch.zeros(len(train_labels))\n",
        "weights[np.argwhere(train_labels == 0)] = class_weights[0]\n",
        "weights[np.argwhere(train_labels == 1)] = class_weights[1]\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss(weight=weights).to(device)\n",
        "\n",
        "optimizer = Adam(nn_mi.parameters(), lr=4e-5)\n",
        "n_epochs = 100\n",
        "\n",
        "for i in range(n_epochs):\n",
        "  nn_mi.train()\n",
        "  optimizer.zero_grad()\n",
        "  output = nn_mi(torch.Tensor(X_train).to(device), train_bags)\n",
        "  loss = criterion(output, torch.Tensor(train_labels).to(device))\n",
        "  loss.backward()\n",
        "  optimizer.step() \n",
        "\n",
        "nn_mi.eval()\n",
        "with torch.no_grad():\n",
        "  y_pred_nn_test = torch.sigmoid(nn_mi(torch.Tensor(X_test).to(device), test_bags)).detach().cpu().numpy().flatten()\n",
        "  print(\"ROC AUC: {}\".format(get_roc_auc(test_labels, y_pred_nn_test)))\n",
        "  print(\"PR AUC: {}\".format(get_pr_auc(test_labels, y_pred_nn_test)))\n",
        "  print(\"Accuracy Score: {}\".format(accuracy_score(test_labels, y_pred_nn_test >= 0.5)))\n",
        "  print(\"Balanced Accuracy Score: {}\".format(balanced_accuracy_score(test_labels, y_pred_nn_test >= 0.5)))\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROC AUC: 0.7740915675156472\n",
            "PR AUC: 0.2557849172870432\n",
            "Accuracy Score: 0.11891891891891893\n",
            "Balanced Accuracy Score: 0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DfhEnGdhPob"
      },
      "source": [
        "class nnMIMax(nn.Module):\n",
        "\n",
        "  def __init__(self, encoder, decoder, mode='max'):\n",
        "    super(nnMIMax, self).__init__()\n",
        "    if mode not in ('max', 'mean'):\n",
        "      raise ValueError(\"Invalid mode {}, must be one of max or mean\".format(mode))\n",
        "    self.mode = mode\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    \n",
        "  def forward(self, x, indices):\n",
        "    x = self.encoder(x)\n",
        "    if self.mode == 'max':\n",
        "      x = torch.stack([torch.max(x[idx], axis=0).values for idx in indices])\n",
        "    else:\n",
        "      x = torch.stack([torch.mean(x[idx], axis=0).values for idx in indices])\n",
        "    x = self.decoder(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXDArRCeKLPp",
        "outputId": "34997f12-dd15-4db2-886f-eb44ab776cc7"
      },
      "source": [
        "device = 'cuda'\n",
        "\n",
        "nn_mi = nnMIMax(nn.Sequential(*[nn.Linear(64, 128), nn.ReLU(),\n",
        "                               nn.Linear(128, 64), nn.ReLU()]),\n",
        "                nn.Sequential(*[nn.Linear(64, 128), nn.ReLU(), \n",
        "                                nn.Linear(128, 64), nn.ReLU(),\n",
        "                                nn.Linear(64, 1)]), mode='max').to(device)\n",
        "\n",
        "classes, counts = np.unique(train_labels, return_counts=True)\n",
        "class_weights = 1./torch.tensor(counts, dtype=torch.float)\n",
        "class_weights = class_weights / class_weights.sum()\n",
        "\n",
        "weights = torch.zeros(len(train_labels))\n",
        "weights[np.argwhere(train_labels == 0)] = class_weights[0]\n",
        "weights[np.argwhere(train_labels == 1)] = class_weights[1]\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss(weight=weights).to(device)\n",
        "\n",
        "optimizer = Adam(nn_mi.parameters(), lr=4e-3)\n",
        "n_epochs = 100\n",
        "\n",
        "for i in range(n_epochs):\n",
        "  nn_mi.train()\n",
        "  optimizer.zero_grad()\n",
        "  output = nn_mi(torch.Tensor(X_train).to(device), train_bags)\n",
        "  loss = criterion(output.flatten(), torch.Tensor(train_labels).to(device))\n",
        "  loss.backward()\n",
        "  optimizer.step() \n",
        "\n",
        "nn_mi.eval()\n",
        "with torch.no_grad():\n",
        "  y_pred_nn_test = torch.sigmoid(nn_mi(torch.Tensor(X_test).to(device), test_bags)).detach().cpu().numpy().flatten()\n",
        "  print(\"ROC AUC: {}\".format(get_roc_auc(test_labels, y_pred_nn_test)))\n",
        "  print(\"PR AUC: {}\".format(get_pr_auc(test_labels, y_pred_nn_test)))\n",
        "  print(\"Accuracy Score: {}\".format(accuracy_score(test_labels, y_pred_nn_test >= 0.5)))\n",
        "  print(\"Balanced Accuracy Score: {}\".format(balanced_accuracy_score(test_labels, y_pred_nn_test >= 0.5)))\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROC AUC: 0.9342233686558841\n",
            "PR AUC: 0.7028383752189724\n",
            "Accuracy Score: 0.9198198198198199\n",
            "Balanced Accuracy Score: 0.8283486707566463\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHqWcTeOyYTE"
      },
      "source": [
        "class nnMIAttention(nn.Module):\n",
        "\n",
        "  def __init__(self, encoder, decoder, mode='max'):\n",
        "    super(nnMIMax, self).__init__()\n",
        "    if mode not in ('max', 'mean'):\n",
        "      raise ValueError(\"Invalid mode {}, must be one of max or mean\".format(mode))\n",
        "    self.mode = mode\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    \n",
        "  def forward(self, x, indices):\n",
        "    x = self.encoder(x)\n",
        "    if self.mode == 'max':\n",
        "      x = torch.stack([torch.max(x[idx], axis=0).values for idx in indices])\n",
        "    else:\n",
        "      x = torch.stack([torch.mean(x[idx], axis=0).values for idx in indices])\n",
        "    x = self.decoder(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}